{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_lhzUjEU052V",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "# Decision Stump\n",
        "\n",
        "\n",
        "\n",
        "### Learning Objectives \n",
        "- Construct a decision stump with a split on one node and use the majority vote algorithm at leaf nodes\n",
        "- Become familiar with a machine learning algorithm and mindset\n",
        "- Gain further familiarity coding in Python and related modules (e.g. NumPy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "wdFi_3uBfmGb",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "<a name=\"data\"></a>\n",
        "\n",
        "# Part I: Data Inspection\n",
        "\n",
        "We begin by inspecting the dataset. For this assignment, we use a modified version of the *heartFailure dataset*, which contains heart failure clinical records. The original dataset consists of 299 instances and 13 attributes (*e.g.* age, diabetes, smoking, etc.). **In this assignment, we only  handle attributes with binary values** (*e.g.* 0/1, yes/no).  The modified dataset consists of 299 instances and 5 binary attributes. More information on the heartFailure dataset can be found on this [link](https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xP1H6IFaPhiS"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "from testing import TestHelper\n",
        "\n",
        "TOY_TRAIN_FILE = './data/toy_train.csv'     # filepath of toy_train dataset\n",
        "TOY_TEST_FILE = './data/toy_test.csv'       # filepath of toy_test dataset\n",
        "FULL_TRAIN_FILE = './data/full_train.csv'   # filepath of full_train dataset\n",
        "FULL_TEST_FILE = './data/full_test.csv'     # filepath of full_test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "2c6XaZOTbtki",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "Run the cell below to visualize the `toy_train` dataset. The first column is a pandas DataFrame index column that can be ignored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqVH7IkVb18X",
        "outputId": "4b2169a7-5017-4436-87a9-6c105d7a4d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   high_blood_pressure  smoking  DEATH_EVENT\n",
            "0                    0        0            0\n",
            "1                    1        0            0\n",
            "2                    1        0            1\n",
            "3                    0        1            0\n",
            "4                    0        1            1\n",
            "5                    0        0            1\n",
            "6                    0        0            0\n",
            "7                    1        1            1\n",
            "8                    0        0            0\n",
            "9                    0        1            0\n"
          ]
        }
      ],
      "source": [
        "toy_train = pd.read_csv(TOY_TRAIN_FILE) # load data into a panda DataFrame\n",
        "toy_test = pd.read_csv(TOY_TEST_FILE)\n",
        "print(toy_train)                        # show toy_train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "T1-v2hA3f4Wr",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "To help you with data preprocessing, we provide you with the function `load_data` that \n",
        "takes in a filepath of the train/test dataset and output a tuple of `(X, Y, attribute_names)`, where: \n",
        "- `X` is a NumPy array with $N$ rows and $M$ columns (*i.e.* shape `(N, M)`), where $N, M$ denote the number of instances and attributes, respectively\n",
        "- `Y` is a NumPy array with shape `(N, )`, where $N$ is number of instances. **Note**: there is a crucial difference between shape `(N,)` vs. `(N, 1)` in NumPy: The former represents an 1-dimension array with $N$ elements, while the latter represents a 2-D array with $N$ rows and 1 column.\n",
        "- `attribute_names`: a list of string, with the index corresponds to the column index of `X` (*e.g.* `['high_blood_pressure', 'smoking']`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "v7gRT-wyODiW"
      },
      "outputs": [],
      "source": [
        "def load_data(filename: str) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
        "    \"\"\"This function takes in the filepath of the data and outputs the tuple of \n",
        "    (X, Y, attribute_names). This reader assumes the label Y is always positioned \n",
        "    at the last column\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename: type `str`\n",
        "        The filepath to the dataset\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A tuple (X, Y, attributes_name) where\n",
        "        X: type `np.ndarray`, shape (N, M)\n",
        "            Numpy arrays with N rows, M columns containing the attribute values for N training instances\n",
        "        Y: type `np.ndarray`, shape (N, )\n",
        "            Numpy arrays with N rows containing the true labels for N training instances\n",
        "        attribute_names: type `List[str]`\n",
        "            Names of the attributes\n",
        "    \"\"\"\n",
        "    X: List[str] = []\n",
        "    Y: List[str] = []\n",
        "    attribute_names: List[str] = []\n",
        "    with open(filename, 'r') as f: \n",
        "        reader = csv.reader(f)\n",
        "\n",
        "        # get attribute list, get rid of label header\n",
        "        attribute_names = next(reader)[:-1] \n",
        "\n",
        "        # get X, Y values and convert them to numpy arrays\n",
        "        for row in reader: \n",
        "            X.append(row[:-1])\n",
        "            Y.append(row[-1])\n",
        "        X = np.array(X)\n",
        "        Y = np.array(Y)\n",
        "\n",
        "    return (X, Y, attribute_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "qvvoa36XOEBn",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "Load the following cell to visualize `X`, `Y`, and `attribute_names` of the `toy_train` dataset. Don't forget to load the cell containing `load_data` function above. Questions 1 - 3 then check your understanding of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTj__1FlShPv",
        "outputId": "d37de182-eaa9-458c-80b6-09ec8f601468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X = (10, 2)\n",
            "X =  [['0' '0']\n",
            " ['1' '0']\n",
            " ['1' '0']\n",
            " ['0' '1']\n",
            " ['0' '1']\n",
            " ['0' '0']\n",
            " ['0' '0']\n",
            " ['1' '1']\n",
            " ['0' '0']\n",
            " ['0' '1']]\n",
            "Shape of Y =  (10,)\n",
            "Y =  ['0' '0' '1' '0' '1' '1' '0' '1' '0' '0']\n",
            "attribute_names = ['high_blood_pressure', 'smoking']\n"
          ]
        }
      ],
      "source": [
        "toy_X_train, toy_Y_train, toy_attributes = load_data(TOY_TRAIN_FILE)\n",
        "print('Shape of X =', toy_X_train.shape)\n",
        "print('X = ', toy_X_train)\n",
        "print('Shape of Y = ', toy_Y_train.shape)\n",
        "print('Y = ', toy_Y_train)\n",
        "print('attribute_names =', toy_attributes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "RvZ0U2gPC3Lq",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "[Back to top](#index)\n",
        "\n",
        "<a name=\"q1\"></a>\n",
        "### Question 1: Number of Attribute [5 pt]\n",
        "What is the number of attributes in the `toy_train` dataset? Assign your answer as a Python integer to variable `ans1` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5ChcTFWCzrx"
      },
      "outputs": [],
      "source": [
        "\n",
        "ans1 = toy_X_train.shape[1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-fiumfFqCiiU",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "\n",
        "### Name of Attribute \n",
        "\n",
        "What attribute does column index 1 of `X` in `toy_train` represent? Note that in Python, indexing starts from 0 (*i.e.* index 0 denotes the first element). Assign your answer as a Python string to variable `ans2` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36HCOgu5U_fa"
      },
      "outputs": [],
      "source": [
        "\n",
        "ans2 = toy_attributes[1] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "FsVan-mHCi3f",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "\n",
        " \n",
        "### Value of Attribute\n",
        "\n",
        "What are all the possible values of the attribute in question 2, in the heartFailure dataset? Please list them in ascending/alphabetical order in a Python list and assign your answer to variable `ans3` (*e.g.* `ans3 = ['value1', 'value2']`). Each element in the list should have type string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4jQI1XJswYx",
        "outputId": "73c4e4c0-52f2-4e80-b369-fc3abba209d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0', '1']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ans3 = sorted(toy_X_train[1]) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "botpPgthDhTV",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "<a name=\"create-data\"></a>\n",
        "\n",
        "### Create Your Own Data\n",
        "\n",
        "In addition to the `toy` dataset, you are welcome to create your own data for debugging purposes. You can create the data directly in the code block, instead of loading it from a file. Below we show you an example of `X` array with 4 rows (instances) and 2 columns (attributes), and the associated label array `Y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3Jft0r70F1kd"
      },
      "outputs": [],
      "source": [
        "# An example of X array with shape (4, 2) and Y array with shape (4,).\n",
        "# The values are all 0 as placeholder, but you can modify the value \n",
        "# and the arrays as you wish. \n",
        "X = np.array([\n",
        "    ['0','0'],\n",
        "    ['0','0'],\n",
        "    ['0','0'],\n",
        "    ['0','0']\n",
        "])\n",
        "Y = np.array([\n",
        "    '0',\n",
        "    '0',\n",
        "    '0',\n",
        "    '0'\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "wZZKsa8lTAON",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "\n",
        "\n",
        "# Part II: Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-o-4w61hHJBD",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "<a name=\"q4\"></a>\n",
        " Majority Vote \n",
        "\n",
        "To begin, implement a `majority_vote` algorithm that takes in `X, Y` NumPy arrays and outputs the desired label. If there are an equal number of labels, the tie-breaker goes to the label value that appears first in the dataset (*i.e.* if there is an equal number of `'0'` and `'1'`, and `'1'` appears first, then `majority_vote` outputs `'1'`). In addition, you are guaranteed that there is no empty dataset in our test cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbly8B_4VRLy"
      },
      "outputs": [],
      "source": [
        " \n",
        "def majority_vote(X: np.ndarray, Y: np.ndarray) -> str:\n",
        "    \"\"\"This function computes the output label of the given dataset, following the \n",
        "    majority vote algorithm\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X: type `np.ndarray`, shape (N, M)\n",
        "        Numpy arrays with N rows, M columns containing the attribute values for N instances\n",
        "    Y: type `np.ndarray`, shape (N, )\n",
        "        Numpy arrays with N rows containing the true labels for N instances\n",
        "\n",
        "    Returns the majority label\n",
        "    \"\"\"\n",
        "\n",
        "    d = {}\n",
        "    for i in Y:\n",
        "        if i in d:\n",
        "            d[i]+=1\n",
        "        else:\n",
        "            d[i] =1\n",
        "    test_val = list(d.values())[0]\n",
        "  \n",
        "    for ele in d:\n",
        "        if d[ele] != test_val:\n",
        "            inverse = [(value, key) for key, value in d.items()]\n",
        "            return (max(inverse)[1])\n",
        "    return Y[0] \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWMOobA5dfdg",
        "outputId": "bc4f780c-1808-4c2f-cb58-b316efacf063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label= 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X = np.array([\n",
        "    ['0','0'],\n",
        "    ['0','0'],\n",
        "    ['0','0'],\n",
        "    ['0','0']\n",
        "])\n",
        "Y = np.array([\n",
        "    '1',\n",
        "    '0',\n",
        "    '0',\n",
        "    '0'\n",
        "])\n",
        "\n",
        "# call your function on the toy dataset\n",
        "label = majority_vote(X, Y)\n",
        "\n",
        "# print the result\n",
        "print('label=', label) # expected answer is '0', type 'str'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL-oGjaATlsJ",
        "outputId": "2bd85e03-709a-4aad-c4f5-f8b63b835745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# Example output of your majority_vote function on toy train dataset\n",
        "toy_X_train, toy_Y_train, toy_attributes = load_data(TOY_TRAIN_FILE)\n",
        "label = majority_vote(toy_X_train, toy_Y_train)\n",
        "print(label) # expected answer is '0', type 'str'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "MEZQei62Vt88",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "\n",
        "\n",
        "<a name=\"q5\"></a>\n",
        "\n",
        " Split \n",
        "\n",
        "Next, implement a `split` function that takes in a dataset (`X,Y` arrays), \n",
        "the attribute to split on (represented as an column index of `X`), and returns a tuple of the split datasets.\n",
        "Specifically: \n",
        "- For input `X` and `Y`, you should output the tuple `(X_left, Y_left, X_right, Y_right)`, all of type NumPy arrays. \n",
        "- The left and right values of the attribute should be in alphabetical order (e.g. `'0'` on the left, `'1'` on the right). The left sub-dataset (`X_left, Y_left`) should corresponds to the left attribute value, and similarly for the right sub-dataset (`X_right`, `Y_right`).\n",
        "- `X` is guaranteed to be split into 2 non-empty datasets. In other words, the values of the split attributes in `X` is always more than 1 (otherwise, we would already be in a leaf node, and there is no need to keep splitting). As a side note when implementing decision tree, you should always check for this condition before splitting.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j1RGDoXVwNz"
      },
      "outputs": [],
      "source": [
        "\n",
        "def split(X: np.ndarray, \n",
        "          Y: np.ndarray, \n",
        "          split_attribute: int\n",
        "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"This function takes a dataset and splits it into two sub-datasets according \n",
        "    to the values of the split attribute. The left and right values of the split \n",
        "    attribute should be in alphabetical order. The left dataset should correspond \n",
        "    to the left attribute value, and similarly for the right dataset. \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X: type `np.ndarray`, shape (N, M)\n",
        "        Numpy arrays with N rows, M columns containing the attribute values for N instances\n",
        "    Y: type `np.ndarray`, shape (N, )\n",
        "        Numpy arrays with N rows containing the true labels for N instances\n",
        "    split_attribute: type `int`\n",
        "        The index of the attribute to split the dataset on\n",
        "\n",
        "    Returns the tuple of two sub-datasets, i.e. (X_left, Y_left, X_right, Y_right)\n",
        "    \"\"\"\n",
        "    \n",
        "    keys = set()\n",
        "    for i in X:\n",
        "        keys.add(i[split_attribute])\n",
        "        \n",
        "    keys =sorted(list(keys))\n",
        "    X_left, Y_left, X_right, Y_right = [], [], [],[]\n",
        "    for i in range(len(X)):\n",
        "        if X[i][split_attribute] == keys[0]:\n",
        "            X_left.append(X[i])\n",
        "            Y_left.append(Y[i])\n",
        "        else:\n",
        "            X_right.append(X[i])\n",
        "            Y_right.append(Y[i])\n",
        "    return (np.array(X_left), np.array(Y_left), np.array(X_right), np.array(Y_right)) # replace this line with your return statement\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "k59mnQk1LYSI",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "Similar to `majority_vote`, you can inspect your function output by calling `split` on either your own created dataset, or load dataset from file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AaX-17mLePx",
        "outputId": "c2079c89-369a-4bff-9fec-2cbe85bf199c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['0' '0']\n",
            " ['0' '1']]\n"
          ]
        }
      ],
      "source": [
        "# Create a toy dataset for you to debug. Replace X, Y with the test cases that\n",
        "# you did not pass.  You can load dataset with something like\n",
        "# X, Y, attribute = load_data(TOY_TRAIN_FILE)\n",
        "X = np.array([\n",
        "    ['1','0'],\n",
        "    ['1','0'],\n",
        "    ['0','0'],\n",
        "    ['0','1']\n",
        "])\n",
        "Y = np.array([\n",
        "    '1',\n",
        "    '0',\n",
        "    '0',\n",
        "    '0'\n",
        "])\n",
        "split_attribute = 0  \n",
        "\n",
        "# call your function on the toy dataset\n",
        "X_left, Y_left, X_right, Y_right = split(X, Y, split_attribute=split_attribute)\n",
        " \n",
        "# print the result. You can print X_left, Y_left, X_right, Y_right as well\n",
        "print(X_left)\n",
        "# expected result for X_left is \n",
        "# [['0' '0']\n",
        "#  ['0' '1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UM-80dpDhIY4",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "### Train \n",
        "\n",
        "Implement the `train` function for your decision stump. This function takes in train dataset `X_train, Y_train`, and the index of the split attribute `attribute_index`. The output of this function is a tuple of two strings, where the first element of the tuple is the label of the left child node, and the second element is the label of the right child node. \n",
        "\n",
        "."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YRYH0VVhMBi"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(X_train: np.ndarray, Y_train: np.ndarray, attribute_index: int) -> Tuple[str, str]:\n",
        "    \"\"\"This function takes the training dataset and a split attribute and outputs the \n",
        "    tuple of (left_label, right_label), corresponding the label on the left and right \n",
        "    leaf nodes of the decision stump\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X_train: type `np.ndarray`, shape (N, M)\n",
        "        Numpy arrays with N rows, M columns containing the attribute values for N training instances\n",
        "    Y_train: type `np.ndarray`, shape (N, )\n",
        "        Numpy arrays with N rows containing the true labels for N training instances\n",
        "    attribute_index: type `int`\n",
        "        The index of the attribute to split the dataset on\n",
        "\n",
        "    Returns the tuple of labels, i.e. (left_label, right_label)\n",
        "    \"\"\"\n",
        "    \n",
        "    X_left, Y_left, X_right, Y_right = split(X_train, Y_train, split_attribute=split_attribute)\n",
        "    left_label = majority_vote(X_left, Y_left)\n",
        "    right_label = majority_vote(X_right, Y_right)\n",
        "    return (left_label, right_label) # replace this line with your return statement\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ_7EAujn86p",
        "outputId": "b0b5fd10-b271-491a-fc0b-63a2a856b975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "left label = 0\n",
            "right label = 1\n"
          ]
        }
      ],
      "source": [
        "# Create a toy dataset for you to debug. Replace X, Y with the test cases that\n",
        "# you did not pass.  You can load dataset with something like\n",
        "# X, Y, attribute = load_data(TOY_TRAIN_FILE)\n",
        "X = np.array([\n",
        "    ['1','0'],\n",
        "    ['1','0'],\n",
        "    ['0','0'],\n",
        "    ['0','1']\n",
        "])\n",
        "Y = np.array([\n",
        "    '1',\n",
        "    '0',\n",
        "    '0',\n",
        "    '0'\n",
        "])\n",
        "split_attribute = 0  \n",
        "\n",
        "# call your function on the toy dataset\n",
        "left_label, right_label = train(X, Y, attribute_index=split_attribute)\n",
        "\n",
        "# print the result\n",
        "print('left label =', left_label)   # expected result is '0'\n",
        "print('right label =', right_label) # expected result is '1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "V55fNayMhOR5",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "\n",
        "\n",
        "### Predict\n",
        "\n",
        "Implement the `predict` function that takes in your trained stump (output of the `train` function), an `X` array, the split `attribute_index` and predicts the labels of `X`. The output should be a 1-D NumPy array with the same number of elements as instances in `X`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5eLvprTGh0Hv"
      },
      "outputs": [],
      "source": [
        "\n",
        "def predict(left_label: str, right_label: str, X: np.ndarray, attribute_index: int) -> np.ndarray:\n",
        "    \"\"\"This function takes in the output of the train function (left_label, right_label), \n",
        "    the dataset without label (i.e. X), and the split attribute index, and returns the \n",
        "    label predictions for X\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    left_label: type `str`\n",
        "        The label corresponds to the left leaf node of the decision stump\n",
        "    right_label: type `str`\n",
        "        The label corresponds to the right leaf node of the decision stump\n",
        "    X: type `np.ndarray`, shape (N, M)\n",
        "        Numpy arrays with N rows, M columns containing the attribute values for N instances\n",
        "    attribute_index: type `int`\n",
        "        The index of the attribute to split the dataset on\n",
        "\n",
        "    Returns the numpy arrays with shape (N,) containing the label predictions for X\n",
        "    \"\"\"\n",
        "    \n",
        "    ans  =  []\n",
        "    keys = set()\n",
        "    for i in X:\n",
        "        keys.add(i[split_attribute])\n",
        "        \n",
        "    keys =sorted(list(keys))\n",
        "    for i in range(len(X)):\n",
        "        if X[i][split_attribute] == keys[0]:\n",
        "            ans.append(left_label)\n",
        "        else:\n",
        "            ans.append(right_label)\n",
        "        \n",
        "    return np.array(ans) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do4meXr3gHy5",
        "outputId": "899ad669-ce81-42b4-88d7-ce8ecbd0b956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1' '1' '1' '1']\n"
          ]
        }
      ],
      "source": [
        "# Create a toy dataset for you to debug. Replace X, Y with the test cases that\n",
        "# you did not pass. You can load dataset with something like\n",
        "# X, Y, attribute = load_data(TOY_TRAIN_FILE)\n",
        "X = np.array([\n",
        "    ['1', '0'],\n",
        "    ['1', '0'],\n",
        "    ['0', '0'],\n",
        "    ['0', '0']\n",
        "])\n",
        "(left_label, right_label) = ('1', '1')\n",
        "split_attribute = 0  \n",
        "\n",
        "# call your function on the debug dataset\n",
        "Y_pred = predict(left_label, right_label, X, attribute_index=split_attribute)\n",
        "\n",
        "# print the result\n",
        "print(Y_pred) # expected result is ['1' '1' '1' '1']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "uF8qwTndh8rZ",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "\n",
        "### Error Rate\n",
        "\n",
        "Implement the `error_rate` function that takes in the true `Y` values and the `Y_pred` predictions (output of `predict` function) and computes the error rate, which is the number of incorrect instances divided by the number of total instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "t4PEJSUriEGF"
      },
      "outputs": [],
      "source": [
        "\n",
        "def error_rate(Y: np.ndarray, Y_pred: np.ndarray) -> float:    \n",
        "    \"\"\"This function computes the error rate (i.e. number of incorrectly predicted\n",
        "    instances divided by total number of instances)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    Y: type `np.ndarray`, shape (N, )\n",
        "        Numpy arrays with N rows containing the true labels for N instances\n",
        "    Y_pred: type `np.ndarray`, shape (N, )\n",
        "        Numpy arrays with N rows containing the predicted labels for N instances\n",
        "\n",
        "    Returns the error rate, which is a float value between 0 and 1 \n",
        "    \"\"\"\n",
        "    corr = len(Y)\n",
        "    incorr = 0\n",
        "    for i in range(len(Y)):\n",
        "        if Y[i] != Y_pred[i]:\n",
        "            incorr+=1\n",
        "        \n",
        "    return incorr/corr "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruHcjM2pfw3g",
        "outputId": "b361957e-6e31-4b14-8f6a-3135e2771d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.25\n"
          ]
        }
      ],
      "source": [
        "# Create a toy dataset for you to debug. Replace Y, Y_pred with the test cases that\n",
        "# you did not pass.  You can load dataset with something like\n",
        "# X, Y, attribute = load_data(TOY_TRAIN_FILE)\n",
        "Y = np.array(['1','0','0','0'])\n",
        "Y_pred = np.array(['1','1','0','0'])\n",
        "\n",
        "# call your function\n",
        "rate = error_rate(Y, Y_pred)\n",
        "\n",
        "# print the result\n",
        "print(rate) # expected result is 0.25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "HUoFw8PCiN3Y",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "\n",
        "### Putting Everything Together\n",
        "\n",
        "In this last task, you should make use of the previous functions to implement `train_and_test` to obtain the results of your decision stump given a dataset. The function `train_and_test` takes in the filepath of the train dataset, the filepath of the test dataset, the split attribute index, and returns the dictionary containing the relevant outputs (*e.g.* train and test error rates). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VrgRQGGRiTuc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_and_test(train_filename: str, test_filename: str, attribute_index: int) -> Dict[str, Any]:\n",
        "    \"\"\"This function ties the above implemented functions together. The inputs are \n",
        "    filepaths of the train and test datasets as well as the split attribute index. The\n",
        "    output is a dictionary of relevant information (e.g. train and test error rates)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_filename: type `str`\n",
        "        The filepath to the training file\n",
        "    test_filename: type `str`\n",
        "        The filepath to the testing file\n",
        "    attribute_index: type `int`\n",
        "        The index of the attribute to split the dataset on\n",
        "\n",
        "    Returns an output dictionary\n",
        "    \"\"\"\n",
        "    X_train, Y_train, attribute_names = load_data(train_filename) \n",
        "    X_test, Y_test, _ = load_data(test_filename)\n",
        "\n",
        "    left_label, right_label = train(X_train, Y_train, attribute_index) \n",
        "    Y_pred_train = predict(left_label, right_label, X_train, attribute_index) \n",
        "    Y_pred_test = predict(left_label, right_label, X_test, attribute_index) \n",
        "\n",
        "    train_error_rate = error_rate(Y_train, Y_pred_train) \n",
        "    test_error_rate = error_rate(Y_test, Y_pred_test) \n",
        "\n",
        "    return {\n",
        "        'attribute_names' : attribute_names,\n",
        "        'stump'           : (left_label, right_label),\n",
        "        'train_error_rate': train_error_rate,\n",
        "        'test_error_rate' : test_error_rate\n",
        "    }\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tvgBXxJiXNX",
        "scrolled": true,
        "outputId": "585711ae-5646-4959-9c4c-f6cb36605097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./data/full_train.csv\n",
            "./data/full_test.csv\n",
            "0\n",
            "attributes:  ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']\n",
            "stump:  ('0', '0')\n",
            "train error:  0.3\n",
            "test error:  0.3422818791946309\n"
          ]
        }
      ],
      "source": [
        "train_file = FULL_TRAIN_FILE \n",
        "test_file = FULL_TEST_FILE\n",
        "attribute_index = 0\n",
        "\n",
        "#train_file = TOY_TRAIN_FILE\n",
        "#test_file = TOY_TEST_FILE\n",
        "#attribute_index = 0\n",
        "# call your function\n",
        "output_dict = train_and_test(train_file, test_file, attribute_index=attribute_index)\n",
        "print(train_file)\n",
        "print(test_file)\n",
        "print(attribute_index)\n",
        "# print the result\n",
        "print('attributes: ', output_dict['attribute_names'])\n",
        "print('stump: ', output_dict['stump'])  \n",
        "print('train error: ',output_dict['train_error_rate']) # expected result is 0.3\n",
        "print('test error: ', output_dict['test_error_rate']) # expected result is 0.34"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Decision Stump.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 [3.7]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}